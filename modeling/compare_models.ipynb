{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with: ['mmse'] using Random Forest\n",
      "DIAGNOSIS\n",
      "0.0    2280\n",
      "1.0    2280\n",
      "2.0    2280\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.80      0.69       449\n",
      "         1.0       0.56      0.40      0.46       496\n",
      "         2.0       0.80      0.80      0.80       423\n",
      "\n",
      "    accuracy                           0.65      1368\n",
      "   macro avg       0.65      0.66      0.65      1368\n",
      "weighted avg       0.65      0.65      0.64      1368\n",
      "\n",
      "Model trained with: ['mmse'] using Logistic Regression\n",
      "DIAGNOSIS\n",
      "0.0    2280\n",
      "1.0    2280\n",
      "2.0    2280\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.80      0.69       449\n",
      "         1.0       0.56      0.41      0.47       496\n",
      "         2.0       0.82      0.81      0.82       423\n",
      "\n",
      "    accuracy                           0.66      1368\n",
      "   macro avg       0.66      0.67      0.66      1368\n",
      "weighted avg       0.66      0.66      0.65      1368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeon0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with: ['mmse'] using Support Vector Machine\n",
      "DIAGNOSIS\n",
      "0.0    2280\n",
      "1.0    2280\n",
      "2.0    2280\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.74      0.67       449\n",
      "         1.0       0.56      0.43      0.48       496\n",
      "         2.0       0.81      0.83      0.82       423\n",
      "\n",
      "    accuracy                           0.66      1368\n",
      "   macro avg       0.66      0.67      0.66      1368\n",
      "weighted avg       0.65      0.66      0.65      1368\n",
      "\n",
      "Model trained with: ['mmse'] using K-Nearest Neighbors\n",
      "DIAGNOSIS\n",
      "0.0    2280\n",
      "1.0    2280\n",
      "2.0    2280\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.29      0.35       449\n",
      "         1.0       0.42      0.61      0.50       496\n",
      "         2.0       0.84      0.71      0.77       423\n",
      "\n",
      "    accuracy                           0.54      1368\n",
      "   macro avg       0.57      0.54      0.54      1368\n",
      "weighted avg       0.56      0.54      0.54      1368\n",
      "\n",
      "Model trained with: ['mmse'] using Decision Tree\n",
      "DIAGNOSIS\n",
      "0.0    2280\n",
      "1.0    2280\n",
      "2.0    2280\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.81      0.67       449\n",
      "         1.0       0.50      0.35      0.41       496\n",
      "         2.0       0.80      0.73      0.76       423\n",
      "\n",
      "    accuracy                           0.62      1368\n",
      "   macro avg       0.62      0.63      0.61      1368\n",
      "weighted avg       0.62      0.62      0.60      1368\n",
      "\n",
      "Model trained with: ['moca'] using Random Forest\n",
      "DIAGNOSIS\n",
      "0.0    1456\n",
      "1.0    1456\n",
      "2.0    1456\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.69      0.68       286\n",
      "         1.0       0.56      0.56      0.56       283\n",
      "         2.0       0.88      0.84      0.86       305\n",
      "\n",
      "    accuracy                           0.70       874\n",
      "   macro avg       0.70      0.70      0.70       874\n",
      "weighted avg       0.70      0.70      0.70       874\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeon0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with: ['moca'] using Logistic Regression\n",
      "DIAGNOSIS\n",
      "0.0    1456\n",
      "1.0    1456\n",
      "2.0    1456\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.71      0.64       286\n",
      "         1.0       0.50      0.45      0.47       283\n",
      "         2.0       0.86      0.77      0.82       305\n",
      "\n",
      "    accuracy                           0.65       874\n",
      "   macro avg       0.65      0.65      0.64       874\n",
      "weighted avg       0.66      0.65      0.65       874\n",
      "\n",
      "Model trained with: ['moca'] using Support Vector Machine\n",
      "DIAGNOSIS\n",
      "0.0    1456\n",
      "1.0    1456\n",
      "2.0    1456\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.77      0.67       286\n",
      "         1.0       0.54      0.47      0.51       283\n",
      "         2.0       0.89      0.76      0.82       305\n",
      "\n",
      "    accuracy                           0.67       874\n",
      "   macro avg       0.68      0.67      0.67       874\n",
      "weighted avg       0.68      0.67      0.67       874\n",
      "\n",
      "Model trained with: ['moca'] using K-Nearest Neighbors\n",
      "DIAGNOSIS\n",
      "0.0    1456\n",
      "1.0    1456\n",
      "2.0    1456\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.78      0.60       286\n",
      "         1.0       0.40      0.36      0.38       283\n",
      "         2.0       0.90      0.49      0.64       305\n",
      "\n",
      "    accuracy                           0.54       874\n",
      "   macro avg       0.60      0.54      0.54       874\n",
      "weighted avg       0.61      0.54      0.54       874\n",
      "\n",
      "Model trained with: ['moca'] using Decision Tree\n",
      "DIAGNOSIS\n",
      "0.0    1456\n",
      "1.0    1456\n",
      "2.0    1456\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.67      0.64       286\n",
      "         1.0       0.51      0.53      0.52       283\n",
      "         2.0       0.83      0.74      0.78       305\n",
      "\n",
      "    accuracy                           0.65       874\n",
      "   macro avg       0.65      0.65      0.65       874\n",
      "weighted avg       0.66      0.65      0.65       874\n",
      "\n",
      "Model trained with: ['npiq'] using Random Forest\n",
      "DIAGNOSIS\n",
      "0.0    1150\n",
      "1.0    1150\n",
      "2.0    1150\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.79      0.69       242\n",
      "         1.0       0.41      0.37      0.39       208\n",
      "         2.0       0.65      0.54      0.59       240\n",
      "\n",
      "    accuracy                           0.57       690\n",
      "   macro avg       0.56      0.56      0.56       690\n",
      "weighted avg       0.57      0.57      0.56       690\n",
      "\n",
      "Model trained with: ['npiq'] using Logistic Regression\n",
      "DIAGNOSIS\n",
      "0.0    1150\n",
      "1.0    1150\n",
      "2.0    1150\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.83      0.70       242\n",
      "         1.0       0.40      0.35      0.37       208\n",
      "         2.0       0.68      0.51      0.58       240\n",
      "\n",
      "    accuracy                           0.57       690\n",
      "   macro avg       0.56      0.56      0.55       690\n",
      "weighted avg       0.57      0.57      0.56       690\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeon0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with: ['npiq'] using Support Vector Machine\n",
      "DIAGNOSIS\n",
      "0.0    1150\n",
      "1.0    1150\n",
      "2.0    1150\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.77      0.70       242\n",
      "         1.0       0.37      0.37      0.37       208\n",
      "         2.0       0.63      0.51      0.56       240\n",
      "\n",
      "    accuracy                           0.56       690\n",
      "   macro avg       0.55      0.55      0.54       690\n",
      "weighted avg       0.55      0.56      0.55       690\n",
      "\n",
      "Model trained with: ['npiq'] using K-Nearest Neighbors\n",
      "DIAGNOSIS\n",
      "0.0    1150\n",
      "1.0    1150\n",
      "2.0    1150\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.82      0.68       242\n",
      "         1.0       0.40      0.37      0.38       208\n",
      "         2.0       0.65      0.43      0.52       240\n",
      "\n",
      "    accuracy                           0.55       690\n",
      "   macro avg       0.54      0.54      0.53       690\n",
      "weighted avg       0.55      0.55      0.53       690\n",
      "\n",
      "Model trained with: ['npiq'] using Decision Tree\n",
      "DIAGNOSIS\n",
      "0.0    1150\n",
      "1.0    1150\n",
      "2.0    1150\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.79      0.68       242\n",
      "         1.0       0.41      0.40      0.41       208\n",
      "         2.0       0.67      0.46      0.55       240\n",
      "\n",
      "    accuracy                           0.56       690\n",
      "   macro avg       0.56      0.55      0.55       690\n",
      "weighted avg       0.57      0.56      0.55       690\n",
      "\n",
      "Model trained with: ['mmse', 'moca'] using Random Forest\n",
      "DIAGNOSIS\n",
      "0.0    1103\n",
      "1.0    1103\n",
      "2.0    1103\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.69      0.67       217\n",
      "         1.0       0.58      0.55      0.56       225\n",
      "         2.0       0.88      0.89      0.88       220\n",
      "\n",
      "    accuracy                           0.71       662\n",
      "   macro avg       0.71      0.71      0.71       662\n",
      "weighted avg       0.71      0.71      0.71       662\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeon0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with: ['mmse', 'moca'] using Logistic Regression\n",
      "DIAGNOSIS\n",
      "0.0    1103\n",
      "1.0    1103\n",
      "2.0    1103\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.72      0.64       217\n",
      "         1.0       0.50      0.41      0.45       225\n",
      "         2.0       0.88      0.83      0.86       220\n",
      "\n",
      "    accuracy                           0.65       662\n",
      "   macro avg       0.66      0.66      0.65       662\n",
      "weighted avg       0.66      0.65      0.65       662\n",
      "\n",
      "Model trained with: ['mmse', 'moca'] using Support Vector Machine\n",
      "DIAGNOSIS\n",
      "0.0    1103\n",
      "1.0    1103\n",
      "2.0    1103\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.79      0.65       217\n",
      "         1.0       0.50      0.32      0.39       225\n",
      "         2.0       0.89      0.85      0.87       220\n",
      "\n",
      "    accuracy                           0.65       662\n",
      "   macro avg       0.65      0.65      0.64       662\n",
      "weighted avg       0.65      0.65      0.64       662\n",
      "\n",
      "Model trained with: ['mmse', 'moca'] using K-Nearest Neighbors\n",
      "DIAGNOSIS\n",
      "0.0    1103\n",
      "1.0    1103\n",
      "2.0    1103\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.82      0.62       217\n",
      "         1.0       0.49      0.38      0.43       225\n",
      "         2.0       0.96      0.55      0.70       220\n",
      "\n",
      "    accuracy                           0.58       662\n",
      "   macro avg       0.65      0.58      0.58       662\n",
      "weighted avg       0.65      0.58      0.58       662\n",
      "\n",
      "Model trained with: ['mmse', 'moca'] using Decision Tree\n",
      "DIAGNOSIS\n",
      "0.0    1103\n",
      "1.0    1103\n",
      "2.0    1103\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.65      0.62       217\n",
      "         1.0       0.52      0.51      0.52       225\n",
      "         2.0       0.80      0.76      0.78       220\n",
      "\n",
      "    accuracy                           0.64       662\n",
      "   macro avg       0.64      0.64      0.64       662\n",
      "weighted avg       0.64      0.64      0.64       662\n",
      "\n",
      "Model trained with: ['mmse', 'npiq'] using Random Forest\n",
      "DIAGNOSIS\n",
      "0.0    1147\n",
      "1.0    1147\n",
      "2.0    1147\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.82      0.79       243\n",
      "         1.0       0.56      0.55      0.56       206\n",
      "         2.0       0.84      0.78      0.81       240\n",
      "\n",
      "    accuracy                           0.73       689\n",
      "   macro avg       0.72      0.72      0.72       689\n",
      "weighted avg       0.73      0.73      0.73       689\n",
      "\n",
      "Model trained with: ['mmse', 'npiq'] using Logistic Regression\n",
      "DIAGNOSIS\n",
      "0.0    1147\n",
      "1.0    1147\n",
      "2.0    1147\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.78      0.77       243\n",
      "         1.0       0.54      0.57      0.55       206\n",
      "         2.0       0.86      0.79      0.82       240\n",
      "\n",
      "    accuracy                           0.72       689\n",
      "   macro avg       0.72      0.71      0.71       689\n",
      "weighted avg       0.73      0.72      0.72       689\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeon0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with: ['mmse', 'npiq'] using Support Vector Machine\n",
      "DIAGNOSIS\n",
      "0.0    1147\n",
      "1.0    1147\n",
      "2.0    1147\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.79      0.78       243\n",
      "         1.0       0.56      0.59      0.57       206\n",
      "         2.0       0.86      0.79      0.82       240\n",
      "\n",
      "    accuracy                           0.73       689\n",
      "   macro avg       0.73      0.72      0.72       689\n",
      "weighted avg       0.74      0.73      0.73       689\n",
      "\n",
      "Model trained with: ['mmse', 'npiq'] using K-Nearest Neighbors\n",
      "DIAGNOSIS\n",
      "0.0    1147\n",
      "1.0    1147\n",
      "2.0    1147\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.76      0.69       243\n",
      "         1.0       0.43      0.47      0.45       206\n",
      "         2.0       0.85      0.59      0.70       240\n",
      "\n",
      "    accuracy                           0.61       689\n",
      "   macro avg       0.63      0.61      0.61       689\n",
      "weighted avg       0.64      0.61      0.62       689\n",
      "\n",
      "Model trained with: ['mmse', 'npiq'] using Decision Tree\n",
      "DIAGNOSIS\n",
      "0.0    1147\n",
      "1.0    1147\n",
      "2.0    1147\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.85      0.77       243\n",
      "         1.0       0.44      0.37      0.41       206\n",
      "         2.0       0.75      0.70      0.73       240\n",
      "\n",
      "    accuracy                           0.66       689\n",
      "   macro avg       0.63      0.64      0.64       689\n",
      "weighted avg       0.64      0.66      0.65       689\n",
      "\n",
      "Model trained with: ['moca', 'npiq'] using Random Forest\n",
      "DIAGNOSIS\n",
      "0.0    51\n",
      "1.0    51\n",
      "2.0    51\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.70      0.78        10\n",
      "         1.0       0.73      0.89      0.80         9\n",
      "         2.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.87        31\n",
      "   macro avg       0.87      0.86      0.86        31\n",
      "weighted avg       0.88      0.87      0.87        31\n",
      "\n",
      "Model trained with: ['moca', 'npiq'] using Logistic Regression\n",
      "DIAGNOSIS\n",
      "0.0    51\n",
      "1.0    51\n",
      "2.0    51\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.70      0.78        10\n",
      "         1.0       0.70      0.78      0.74         9\n",
      "         2.0       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.83      0.83      0.82        31\n",
      "weighted avg       0.84      0.84      0.84        31\n",
      "\n",
      "Model trained with: ['moca', 'npiq'] using Support Vector Machine\n",
      "DIAGNOSIS\n",
      "0.0    51\n",
      "1.0    51\n",
      "2.0    51\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.80      0.59        10\n",
      "         1.0       0.20      0.11      0.14         9\n",
      "         2.0       0.89      0.67      0.76        12\n",
      "\n",
      "    accuracy                           0.55        31\n",
      "   macro avg       0.52      0.53      0.50        31\n",
      "weighted avg       0.55      0.55      0.53        31\n",
      "\n",
      "Model trained with: ['moca', 'npiq'] using K-Nearest Neighbors\n",
      "DIAGNOSIS\n",
      "0.0    51\n",
      "1.0    51\n",
      "2.0    51\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.80      0.53        10\n",
      "         1.0       0.43      0.33      0.38         9\n",
      "         2.0       1.00      0.33      0.50        12\n",
      "\n",
      "    accuracy                           0.48        31\n",
      "   macro avg       0.61      0.49      0.47        31\n",
      "weighted avg       0.64      0.48      0.47        31\n",
      "\n",
      "Model trained with: ['moca', 'npiq'] using Decision Tree\n",
      "DIAGNOSIS\n",
      "0.0    51\n",
      "1.0    51\n",
      "2.0    51\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.40      0.47        10\n",
      "         1.0       0.50      0.78      0.61         9\n",
      "         2.0       0.90      0.75      0.82        12\n",
      "\n",
      "    accuracy                           0.65        31\n",
      "   macro avg       0.66      0.64      0.63        31\n",
      "weighted avg       0.68      0.65      0.65        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeon0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with: ['mmse', 'moca', 'npiq'] using Random Forest\n",
      "DIAGNOSIS\n",
      "0.0    51\n",
      "1.0    51\n",
      "2.0    51\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.67      0.73        12\n",
      "         1.0       0.60      0.67      0.63         9\n",
      "         2.0       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.77        31\n",
      "   macro avg       0.77      0.78      0.77        31\n",
      "weighted avg       0.78      0.77      0.77        31\n",
      "\n",
      "Model trained with: ['mmse', 'moca', 'npiq'] using Logistic Regression\n",
      "DIAGNOSIS\n",
      "0.0    51\n",
      "1.0    51\n",
      "2.0    51\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.75      0.78        12\n",
      "         1.0       0.60      0.67      0.63         9\n",
      "         2.0       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.77        31\n",
      "   macro avg       0.77      0.77      0.77        31\n",
      "weighted avg       0.78      0.77      0.78        31\n",
      "\n",
      "Model trained with: ['mmse', 'moca', 'npiq'] using Support Vector Machine\n",
      "DIAGNOSIS\n",
      "0.0    51\n",
      "1.0    51\n",
      "2.0    51\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.67      0.70        12\n",
      "         1.0       0.33      0.44      0.38         9\n",
      "         2.0       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.55        31\n",
      "   macro avg       0.56      0.54      0.54        31\n",
      "weighted avg       0.58      0.55      0.56        31\n",
      "\n",
      "Model trained with: ['mmse', 'moca', 'npiq'] using K-Nearest Neighbors\n",
      "DIAGNOSIS\n",
      "0.0    51\n",
      "1.0    51\n",
      "2.0    51\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67        12\n",
      "         1.0       0.75      0.33      0.46         9\n",
      "         2.0       0.67      0.20      0.31        10\n",
      "\n",
      "    accuracy                           0.55        31\n",
      "   macro avg       0.64      0.51      0.48        31\n",
      "weighted avg       0.63      0.55      0.49        31\n",
      "\n",
      "Model trained with: ['mmse', 'moca', 'npiq'] using Decision Tree\n",
      "DIAGNOSIS\n",
      "0.0    51\n",
      "1.0    51\n",
      "2.0    51\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.67      0.73        12\n",
      "         1.0       0.60      0.67      0.63         9\n",
      "         2.0       0.82      0.90      0.86        10\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.74      0.74      0.74        31\n",
      "weighted avg       0.75      0.74      0.74        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeon0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from pipeline import *    \n",
    "import pandas as pd\n",
    "import itertools\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression  # New import\n",
    "from sklearn.svm import SVC                         # New import\n",
    "from sklearn.neighbors import KNeighborsClassifier   # New import\n",
    "from sklearn.tree import DecisionTreeClassifier      # New import\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "questionnaires = [\n",
    "    ('mmse', 'data/mmse.csv', CRITERIA_MMSE),\n",
    "    ('moca', 'data/moca.csv', CRITERIA_MOCA),\n",
    "    ('npiq', 'data/npiq.csv', CRITERIA_NPIQ),\n",
    "]\n",
    "\n",
    "diagnosis_path = 'data/diagnosis.csv'\n",
    "\n",
    "# Iterate over all combinations\n",
    "for n in range(1, len(questionnaires) + 1):\n",
    "    for combo in itertools.combinations(questionnaires, n):\n",
    "        combo_names = [q[0] for q in combo]\n",
    "        data_paths = [q[1] for q in combo]\n",
    "        criterias = [q[2] for q in combo]\n",
    "\n",
    "        # Load and preprocess data\n",
    "        X, y = load_and_preprocess(data_paths, criterias, diagnosis_path, balance=True)\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        # Define classifiers to test\n",
    "        classifiers = [\n",
    "            ('Random Forest', RandomForestClassifier(n_estimators=100)),\n",
    "            ('Logistic Regression', LogisticRegression()),\n",
    "            ('Support Vector Machine', SVC()),\n",
    "            ('K-Nearest Neighbors', KNeighborsClassifier()),\n",
    "            ('Decision Tree', DecisionTreeClassifier())\n",
    "        ]\n",
    "\n",
    "        # Iterate over classifiers\n",
    "        for clf_name, clf in classifiers:\n",
    "            # Train the model\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            y_pred = clf.predict(X_test)\n",
    "            print(f\"Model trained with: {combo_names} using {clf_name}\")\n",
    "            print(y.value_counts())\n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # Remove or comment out the model saving part\n",
    "        # model_filename = 'saved_models/'+'rf_' + '_'.join(combo_names) + '.pkl'\n",
    "        # joblib.dump((clf, X.columns.tolist()), model_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
